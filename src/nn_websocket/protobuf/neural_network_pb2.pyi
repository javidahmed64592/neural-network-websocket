"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""

import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _ActivationFunction:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _ActivationFunctionEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ActivationFunction.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    LINEAR: _ActivationFunction.ValueType  # 0
    RELU: _ActivationFunction.ValueType  # 1
    SIGMOID: _ActivationFunction.ValueType  # 2

class ActivationFunction(_ActivationFunction, metaclass=_ActivationFunctionEnumTypeWrapper): ...

LINEAR: ActivationFunction.ValueType  # 0
RELU: ActivationFunction.ValueType  # 1
SIGMOID: ActivationFunction.ValueType  # 2
global___ActivationFunction = ActivationFunction

@typing.final
class NeuralNetworkConfig(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    NUM_NETWORKS_FIELD_NUMBER: builtins.int
    NUM_INPUTS_FIELD_NUMBER: builtins.int
    NUM_OUTPUTS_FIELD_NUMBER: builtins.int
    HIDDEN_LAYER_SIZES_FIELD_NUMBER: builtins.int
    WEIGHTS_MIN_FIELD_NUMBER: builtins.int
    WEIGHTS_MAX_FIELD_NUMBER: builtins.int
    BIAS_MIN_FIELD_NUMBER: builtins.int
    BIAS_MAX_FIELD_NUMBER: builtins.int
    INPUT_ACTIVATION_FIELD_NUMBER: builtins.int
    HIDDEN_ACTIVATION_FIELD_NUMBER: builtins.int
    OUTPUT_ACTIVATION_FIELD_NUMBER: builtins.int
    num_networks: builtins.int
    num_inputs: builtins.int
    num_outputs: builtins.int
    weights_min: builtins.float
    weights_max: builtins.float
    bias_min: builtins.float
    bias_max: builtins.float
    input_activation: global___ActivationFunction.ValueType
    hidden_activation: global___ActivationFunction.ValueType
    output_activation: global___ActivationFunction.ValueType
    @property
    def hidden_layer_sizes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]: ...
    def __init__(
        self,
        *,
        num_networks: builtins.int = ...,
        num_inputs: builtins.int = ...,
        num_outputs: builtins.int = ...,
        hidden_layer_sizes: collections.abc.Iterable[builtins.int] | None = ...,
        weights_min: builtins.float = ...,
        weights_max: builtins.float = ...,
        bias_min: builtins.float = ...,
        bias_max: builtins.float = ...,
        input_activation: global___ActivationFunction.ValueType = ...,
        hidden_activation: global___ActivationFunction.ValueType = ...,
        output_activation: global___ActivationFunction.ValueType = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["bias_max", b"bias_max", "bias_min", b"bias_min", "hidden_activation", b"hidden_activation", "hidden_layer_sizes", b"hidden_layer_sizes", "input_activation", b"input_activation", "num_inputs", b"num_inputs", "num_networks", b"num_networks", "num_outputs", b"num_outputs", "output_activation", b"output_activation", "weights_max", b"weights_max", "weights_min", b"weights_min"]) -> None: ...

global___NeuralNetworkConfig = NeuralNetworkConfig
